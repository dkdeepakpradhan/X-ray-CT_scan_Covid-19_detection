{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RETRAIN RESNET50",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkDsGdd3iVS2",
        "outputId": "b2af19ff-40df-4344-8208-e8455aa044fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd \"/content/drive/My Drive/Xray/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/.shortcut-targets-by-id/1jTYiDXauUNccfsOBLyb8M2KSfb1N8T8A/Xray\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ91ULwRjnbp",
        "outputId": "7f443f4b-9a10-4c1d-a818-ae229800cef5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "import PIL.Image as Image\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm,\n",
        "                          target_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "    \"\"\"\n",
        "    given a sklearn confusion matrix (cm), make a nice plot\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
        "\n",
        "    target_names: given classification classes such as [0, 1, 2]\n",
        "                  the class names, for example: ['high', 'medium', 'low']\n",
        "\n",
        "    title:        the text to display at the top of the matrix\n",
        "\n",
        "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
        "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                  plt.get_cmap('jet') or plt.cm.Blues\n",
        "\n",
        "    normalize:    If False, plot the raw numbers\n",
        "                  If True, plot the proportions\n",
        "\n",
        "    Usage\n",
        "    -----\n",
        "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
        "                                                              # sklearn.metrics.confusion_matrix\n",
        "                          normalize    = True,                # show proportions\n",
        "                          target_names = y_labels_vals,       # list of names of the classes\n",
        "                          title        = best_estimator_name) # title of graph\n",
        "\n",
        "    Citiation\n",
        "    ---------\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "    \"\"\"\n",
        "    import itertools\n",
        "\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()\n",
        "\n",
        "def fix_dims(tens):\n",
        "  return np.repeat(tens, 3, -1)\n",
        "\n",
        "labels_path = tf.keras.utils.get_file('ImageNetLabels.txt','https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
        "imagenet_labels = np.array(open(labels_path).read().splitlines())\n",
        "\n",
        "IMAGE_SHAPE = (224, 224)\n",
        "\n",
        "NUM_CLASSES = 3\n",
        "\n",
        "\"\"\"\n",
        "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)#, preprocessing_function=fix_dims)\n",
        "image_data = image_generator.flow_from_directory(\"CT-Data\", target_size=IMAGE_SHAPE, color_mode=\"rgb\", batch_size=128, shuffle=True)#grayscale\n",
        "image_generator2 = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)#, preprocessing_function=fix_dims)\n",
        "val_data = image_generator2.flow_from_directory(\"CT-Data-Youngho\", target_size=IMAGE_SHAPE, color_mode=\"rgb\", batch_size=128, shuffle=False)\n",
        "\n",
        "for image_batch, label_batch in image_data:\n",
        "  print(\"Image batch shape: \", image_batch.shape)\n",
        "  print(\"Label batch shape: \", label_batch.shape)\n",
        "  break\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "first_train = True\n",
        "\n",
        "ckpt_dir1 = \"ckpt1/cp.ckpt\"\n",
        "\n",
        "ckpt_dir2 = \"ckpt2/cp.ckpt\"\n",
        "\n",
        "ckpt_dir3 = \"ckpt3/cp.ckpt\"\n",
        "\n",
        "#feature_extractor_layer = hub.KerasLayer(\"https://tfhub.dev/google/imagenet/pnasnet_large/classification/4\")\n",
        "\n",
        "img_inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "\n",
        "feature_extractor_layer1 = hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\",\n",
        "              trainable=False, input_shape=(224, 224, 3))(img_inputs) #, arguments=dict(batch_norm_momentum=0.997)\n",
        "\n",
        "feature_extractor_layer2 = hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\",\n",
        "              trainable=False, input_shape=(224, 224, 3))(img_inputs) #, arguments=dict(batch_norm_momentum=0.997)\n",
        "\n",
        "feature_extractor_layer3 = hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\",\n",
        "              trainable=False, input_shape=(224, 224, 3))(img_inputs) #, arguments=dict(batch_norm_momentum=0.997)\n",
        "\n",
        "#Make 3 ResNet50 models as KerasLayers\n",
        "\n",
        "dense1 = tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\")(feature_extractor_layer1)\n",
        "\n",
        "dense2 = tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\")(feature_extractor_layer2)\n",
        "\n",
        "dense3 = tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\")(feature_extractor_layer3)\n",
        "\n",
        "#Wrap each in a dense layer for training (because the models are headless)\n",
        "\n",
        "#COMPLETELY NEW BITS\n",
        "#CONCATENATE DENSE LAYERS; THEN ADD RELU CHAIN (which will be trained as the last training step)\n",
        "\n",
        "concat = tf.keras.layers.Concatenate()([dense1, dense2, dense3])\n",
        "\n",
        "relu1 = tf.keras.layers.Dense(units=512, activation='relu')(concat)\n",
        "\n",
        "relu2 = tf.keras.layers.Dense(units=256, activation='relu')(relu1)\n",
        "\n",
        "relu3 = tf.keras.layers.Dense(units=192, activation='relu')(relu2)\n",
        "\n",
        "relu4 = tf.keras.layers.Dense(units=128, activation='relu')(relu3)\n",
        "\n",
        "output = relu2 = tf.keras.layers.Dense(units=3)(relu4)\n",
        "\n",
        "model = tf.keras.Model(inputs=img_inputs, outputs=output, name=\"triple-resnet\")\n",
        "\n",
        "tf.keras.utils.plot_model(model, \"triple-resnet-structure.png\", show_shapes=True)\n",
        "\n",
        "\"\"\"\n",
        "model1 = tf.keras.Sequential([\n",
        "  feature_extractor_layer1,\n",
        "  tf.keras.layers.Dense(image_data.num_classes, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model2 = tf.keras.Sequential([\n",
        "  feature_extractor_layer2,\n",
        "  tf.keras.layers.Dense(image_data.num_classes, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model3 = tf.keras.Sequential([\n",
        "  feature_extractor_layer3,\n",
        "  tf.keras.layers.Dense(image_data.num_classes, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "print(\"Model 1 (Pneumonia):\")\n",
        "model1.summary()\n",
        "\n",
        "print(\"Model 2 (COVID):\")\n",
        "model2.summary()\n",
        "\n",
        "print(\"Model 3 (Regular):\")\n",
        "model3.summary()\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "model1.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(),\n",
        "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['acc'])\n",
        "\n",
        "model2.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(),\n",
        "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['acc'])\n",
        "\n",
        "model3.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(),\n",
        "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['acc'])\n",
        "\n",
        "if first_train:\n",
        "\n",
        "  class CollectBatchStats(tf.keras.callbacks.Callback):\n",
        "    def __init__(self):\n",
        "      self.batch_losses = []\n",
        "      self.batch_acc = []\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "      self.batch_losses.append(logs['loss'])\n",
        "      self.batch_acc.append(logs['acc'])\n",
        "      self.model.reset_metrics()\n",
        "\n",
        "  cp_callback1 = tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_dir1,\n",
        "                                                  save_weights_only=True,\n",
        "                                                  verbose=1)\n",
        "\n",
        "  cp_callback1 = tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_dir2,\n",
        "                                                  save_weights_only=True,\n",
        "                                                  verbose=1)\n",
        "\n",
        "  cp_callback1 = tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_dir3,\n",
        "                                                  save_weights_only=True,\n",
        "                                                  verbose=1)\n",
        "\n",
        "  #Train model 1 (Pneumonia)    \n",
        "\n",
        "  steps_per_epoch = np.ceil(image_data.samples/image_data.batch_size)\n",
        "\n",
        "  batch_stats_callback = CollectBatchStats()\n",
        "\n",
        "  model1.save_weights(ckpt_dir1.format(epoch=0))\n",
        "\n",
        "  history = model1.fit(image_data, epochs=10,\n",
        "                      steps_per_epoch=steps_per_epoch,\n",
        "                      callbacks=[batch_stats_callback, cp_callback1])\n",
        "\n",
        "  plt.figure()\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.xlabel(\"Training Steps\")\n",
        "  plt.ylim([0,2])\n",
        "  plt.plot(batch_stats_callback.batch_losses)\n",
        "\n",
        "\n",
        "  plt.figure()\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.xlabel(\"Training Steps\")\n",
        "  plt.ylim([0,1])\n",
        "  plt.plot(batch_stats_callback.batch_acc)\n",
        "\n",
        "  #Train model 2 (COVID)    \n",
        "\n",
        "  steps_per_epoch = np.ceil(image_data.samples/image_data.batch_size)\n",
        "\n",
        "  batch_stats_callback = CollectBatchStats()\n",
        "\n",
        "  model2.save_weights(ckpt_dir2.format(epoch=0))\n",
        "\n",
        "  history = model2.fit(image_data, epochs=10,\n",
        "                      steps_per_epoch=steps_per_epoch,\n",
        "                      callbacks=[batch_stats_callback, cp_callback2])\n",
        "\n",
        "  plt.figure()\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.xlabel(\"Training Steps\")\n",
        "  plt.ylim([0,2])\n",
        "  plt.plot(batch_stats_callback.batch_losses)\n",
        "\n",
        "\n",
        "  plt.figure()\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.xlabel(\"Training Steps\")\n",
        "  plt.ylim([0,1])\n",
        "  plt.plot(batch_stats_callback.batch_acc)\n",
        "\n",
        "\n",
        "  #Train model 3 (Regular)    \n",
        "\n",
        "  steps_per_epoch = np.ceil(image_data.samples/image_data.batch_size)\n",
        "\n",
        "  batch_stats_callback = CollectBatchStats()\n",
        "\n",
        "  model3.save_weights(ckpt_dir3.format(epoch=0))\n",
        "\n",
        "  history = model3.fit(image_data, epochs=10,\n",
        "                      steps_per_epoch=steps_per_epoch,\n",
        "                      callbacks=[batch_stats_callback, cp_callback3])\n",
        "\n",
        "  plt.figure()\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.xlabel(\"Training Steps\")\n",
        "  plt.ylim([0,2])\n",
        "  plt.plot(batch_stats_callback.batch_losses)\n",
        "\n",
        "\n",
        "  plt.figure()\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.xlabel(\"Training Steps\")\n",
        "  plt.ylim([0,1])\n",
        "  plt.plot(batch_stats_callback.batch_acc)\n",
        "\n",
        "else:\n",
        "  model1.load_weights(tf.train.latest_checkpoint(ckpt_dir1))\n",
        "  model2.load_weights(tf.train.latest_checkpoint(ckpt_dir2))\n",
        "  model3.load_weights(tf.train.latest_checkpoint(ckpt_dir3))\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "label_id = np.argmax(label_batch, axis=-1)\n",
        "\n",
        "class_names = sorted(image_data.class_indices.items(), key=lambda pair:pair[1])\n",
        "class_names = np.array([key.title() for key, value in class_names])\n",
        "predicted_batch = model.predict(val_data)\n",
        "predicted_id = np.argmax(predicted_batch, axis=-1)\n",
        "predicted_label_batch = class_names[predicted_id]\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "plt.figure(figsize=(10,9))\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "for n in range(30):\n",
        "  plt.subplot(6,5,n+1)\n",
        "  plt.imshow(image_batch[n])\n",
        "  color = \"green\" if predicted_id[n] == label_id[n] else \"red\"\n",
        "  plt.title(predicted_label_batch[n].title(), color=color)\n",
        "  plt.axis('off')\n",
        "_ = plt.suptitle(\"Model predictions (green: correct, red: incorrect)\")\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "#label_id = val_data.classes\n",
        "#print(\"Predictions:\", predicted_id)\n",
        "#print(\"Ground truth:\", label_id)\n",
        "\n",
        "#cm = confusion_matrix(predicted_id, label_id)\n",
        "\n",
        "#plot_confusion_matrix(cm, class_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nplt.figure(figsize=(10,9))\\nplt.subplots_adjust(hspace=0.5)\\nfor n in range(30):\\n  plt.subplot(6,5,n+1)\\n  plt.imshow(image_batch[n])\\n  color = \"green\" if predicted_id[n] == label_id[n] else \"red\"\\n  plt.title(predicted_label_batch[n].title(), color=color)\\n  plt.axis(\\'off\\')\\n_ = plt.suptitle(\"Model predictions (green: correct, red: incorrect)\")\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    }
  ]
}